{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from itertools import chain\n",
    "from skimage.io import imread, imshow, imread_collection, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input\n",
    "from keras.layers.core import Lambda, Dropout\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras import backend as K\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Set some parameters\n",
    "IMG_WIDTH = 64\n",
    "IMG_HEIGHT = 64\n",
    "IMG_CHANNELS = 25\n",
    "TRAIN_PATH = 'GeneratedData/train/'\n",
    "TEST_PATH = 'GeneratedData/test/'\n",
    "\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='skimage')\n",
    "seed = 42\n",
    "random.seed = seed\n",
    "np.random.seed = seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get train and test ids\n",
    "train_ids = np.loadtxt(TRAIN_PATH + 'Directory.txt').astype(int)\n",
    "test_ids = np.loadtxt(TEST_PATH + 'Directory.txt').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"train ids(%i):\" % (len(train_ids)), train_ids, \"\\n\")\n",
    "print(\"test ids(%i):\" % (len(test_ids)), test_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.zeros((len(train_ids), IMG_WIDTH, IMG_HEIGHT, IMG_CHANNELS), dtype=np.uint8)\n",
    "Y_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n",
    "\n",
    "# Get train images and masks\n",
    "print('Getting train images and masks ... ')\n",
    "sys.stdout.flush()\n",
    "for n, id in tqdm(enumerate(train_ids), total=len(train_ids)):\n",
    "    img_path = TRAIN_PATH + 'ImageMap-' + str(id) + '.dat'\n",
    "    img_zxy = np.fromfile(img_path, dtype='uint8')\n",
    "    img_zxy.shape = (IMG_CHANNELS, IMG_WIDTH, IMG_HEIGHT)\n",
    "    # convert from 25x64x64 to 64x64x25\n",
    "    img_xyz = np.zeros((IMG_WIDTH, IMG_HEIGHT, IMG_CHANNELS))\n",
    "    for i in range(IMG_CHANNELS):\n",
    "        img_xyz[:,:,i] = img_zxy[i,:,:]\n",
    "    X_train[n] = img_xyz\n",
    "    \n",
    "    mask_path = TRAIN_PATH + 'LabelMap-' + str(id) + '.dat'\n",
    "    mask = np.fromfile(mask_path, dtype=np.bool)\n",
    "    mask.shape = (IMG_WIDTH, IMG_HEIGHT, 1)\n",
    "    Y_train[n] = mask\n",
    "\n",
    "# Get test images and masks\n",
    "print('Getting test images and masks ... ')\n",
    "sys.stdout.flush()\n",
    "X_test = np.zeros((len(test_ids), IMG_WIDTH, IMG_HEIGHT, IMG_CHANNELS), dtype=np.uint8)\n",
    "Y_test = np.zeros((len(test_ids), IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n",
    "for n, id in tqdm(enumerate(test_ids), total=len(test_ids)):\n",
    "    img_path = TEST_PATH + 'ImageMap-' + str(id) + '.dat'\n",
    "    img_zxy = np.fromfile(img_path, dtype='uint8')\n",
    "    img_zxy.shape = (IMG_CHANNELS, IMG_WIDTH, IMG_HEIGHT)\n",
    "    # convert from 25x64x64 to 64x64x25\n",
    "    img_xyz = np.zeros((IMG_WIDTH, IMG_HEIGHT, IMG_CHANNELS))\n",
    "    for i in range(IMG_CHANNELS):\n",
    "        img_xyz[:,:,i] = img_zxy[i,:,:]\n",
    "    X_test[n] = img_xyz\n",
    "    \n",
    "    mask_path = TEST_PATH + 'LabelMap-' + str(id) + '.dat'\n",
    "    mask = np.fromfile(mask_path, dtype=np.bool)\n",
    "    mask.shape = (IMG_WIDTH, IMG_HEIGHT, 1)\n",
    "    Y_test[n] = mask\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if training data looks okay\n",
    "img_idx = random.randint(0, len(train_ids)-1)\n",
    "color_idx = random.randint(0, IMG_CHANNELS-1)\n",
    "imshow(X_train[img_idx,:,:,color_idx])\n",
    "plt.show()\n",
    "imshow(np.squeeze(Y_train[img_idx]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create model\n",
    "\n",
    "Next we build our U-Net model, loosely based on [U-Net: Convolutional Networks for Biomedical Image Segmentation](https://arxiv.org/pdf/1505.04597.pdf) and very similar to [this repo](https://github.com/jocicmarko/ultrasound-nerve-segmentation) from the Kaggle Ultrasound Nerve Segmentation competition.\n",
    "\n",
    "![](https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/u-net-architecture.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build U-Net model\n",
    "inputs = Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
    "\n",
    "# Normalize inputs\n",
    "s = Lambda(lambda x: x / 255) (inputs)\n",
    "# s = inputs\n",
    "\n",
    "# Encoder layers\n",
    "conv0 = Conv2D(4, (3, 3), activation='relu', padding='same') (s)\n",
    "conv0 = Dropout(0.2)(conv0)\n",
    "conv0 = Conv2D(4, (3, 3), activation='relu', padding='same') (conv0)\n",
    "pool0 = MaxPooling2D((2, 2)) (conv0)\n",
    "\n",
    "conv1 = Conv2D(8, (3, 3), activation='relu', padding='same') (pool0)\n",
    "conv1 = Dropout(0.2)(conv1)\n",
    "conv1 = Conv2D(8, (3, 3), activation='relu', padding='same') (conv1)\n",
    "pool1 = MaxPooling2D((2, 2)) (conv1)\n",
    "\n",
    "conv2 = Conv2D(16, (3, 3), activation='relu', padding='same') (pool1)\n",
    "conv2 = Dropout(0.2)(conv2)\n",
    "conv2 = Conv2D(16, (3, 3), activation='relu', padding='same') (conv2)\n",
    "pool2 = MaxPooling2D((2, 2)) (conv2)\n",
    "\n",
    "conv3 = Conv2D(32, (3, 3), activation='relu', padding='same') (pool2)\n",
    "conv3 = Dropout(0.2)(conv3)\n",
    "conv3 = Conv2D(32, (3, 3), activation='relu', padding='same') (conv3)\n",
    "pool3 = MaxPooling2D((2, 2)) (conv3)\n",
    "\n",
    "conv4 = Conv2D(64, (3, 3), activation='relu', padding='same') (pool3)\n",
    "conv4 = Dropout(0.2)(conv4)\n",
    "conv4 = Conv2D(64, (3, 3), activation='relu', padding='same') (conv4)\n",
    "\n",
    "# Decoder layers\n",
    "upconv7 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (conv4)\n",
    "upconv7 = concatenate([upconv7, conv3])\n",
    "conv7 = Conv2D(32, (3, 3), activation='relu', padding='same') (upconv7)\n",
    "conv7 = Conv2D(32, (3, 3), activation='relu', padding='same') (conv7)\n",
    "\n",
    "upconv8 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (conv7)\n",
    "upconv8 = concatenate([upconv8, conv2])\n",
    "conv8 = Conv2D(16, (3, 3), activation='relu', padding='same') (upconv8)\n",
    "conv8 = Conv2D(16, (3, 3), activation='relu', padding='same') (conv8)\n",
    "\n",
    "upconv9 = Conv2DTranspose(8, (2, 2), strides=(2, 2), padding='same') (conv8)\n",
    "upconv9 = concatenate([upconv9, conv1])\n",
    "conv9 = Conv2D(8, (3, 3), activation='relu', padding='same') (upconv9)\n",
    "conv9 = Conv2D(8, (3, 3), activation='relu', padding='same') (conv9)\n",
    "\n",
    "upconv10 = Conv2DTranspose(4, (2, 2), strides=(2, 2), padding='same') (conv9)\n",
    "upconv10 = concatenate([upconv10, conv0], axis=3)\n",
    "conv10 = Conv2D(4, (3, 3), activation='relu', padding='same') (upconv10)\n",
    "conv10 = Conv2D(4, (3, 3), activation='relu', padding='same') (conv10)\n",
    "\n",
    "outputs = Conv2D(1, (1, 1), activation='sigmoid') (conv10)\n",
    "\n",
    "model = Model(inputs=[inputs], outputs=[outputs])\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Training\n",
    "\n",
    "Next we fit the model on the training data, using a validation split of 0.1. We use a small batch size because we have so little data. I recommend using checkpointing and early stopping when training your model. I won't do it here to make things a bit more reproducible (although it's very likely that your results will be different anyway)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model\n",
    "earlystopper = EarlyStopping(patience=5, verbose=1)\n",
    "checkpointer = ModelCheckpoint('model-SonarNet-1.h5', verbose=1, save_best_only=True)\n",
    "results = model.fit(X_train, Y_train, validation_split=0.1, batch_size=8, epochs=30, \n",
    "                   callbacks=[earlystopper, checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.plot(results.history['acc'])\n",
    "plt.plot(results.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation loss values\n",
    "plt.plot(results.history['loss'])\n",
    "plt.plot(results.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on train, val and test\n",
    "model = load_model('model-SonarNet-1.h5', custom_objects={})\n",
    "\n",
    "preds_train = model.predict(X_train[:int(X_train.shape[0]*0.75)], verbose=1)\n",
    "preds_val = model.predict(X_train[int(X_train.shape[0]*0.75):], verbose=1)\n",
    "preds_test = model.predict(X_test, verbose=1)\n",
    "\n",
    "# Threshold predictions\n",
    "preds_train_t = (preds_train > 0.5).astype(np.uint8)\n",
    "preds_val_t = (preds_val > 0.5).astype(np.uint8)\n",
    "preds_test_t = (preds_test > 0.5).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a sanity check on some random training samples\n",
    "img_idx = random.randint(0, len(preds_train_t)-1)\n",
    "color_idx = random.randint(0, IMG_CHANNELS-1)\n",
    "\n",
    "imshow(X_train[img_idx,:,:,color_idx])\n",
    "plt.title(\"Image (1 color plane)\")\n",
    "plt.show()\n",
    "plt.title(\"True mask\")\n",
    "imshow(np.squeeze(Y_train[img_idx]))\n",
    "plt.show()\n",
    "plt.title(\"Predicted mask\")\n",
    "imshow(np.squeeze(preds_train_t[img_idx]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a sanity check on some random validation samples\n",
    "img_idx = random.randint(0, len(preds_val_t)-1)\n",
    "color_idx = random.randint(0, IMG_CHANNELS-1)\n",
    "\n",
    "imshow(X_train[img_idx,:,:,color_idx])\n",
    "plt.title(\"Image (1 color plane)\")\n",
    "plt.show()\n",
    "plt.title(\"True mask\")\n",
    "imshow(np.squeeze(Y_train[img_idx]))\n",
    "plt.show()\n",
    "plt.title(\"Predicted mask\")\n",
    "imshow(np.squeeze(preds_train_t[img_idx]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evalute on test data\n",
    "loss, accuracy = model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loss: \", loss)\n",
    "print(\"Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show all images\n",
    "for img in X_train:\n",
    "    imshow(img[:,:,15])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show all masks\n",
    "for mask in Y_train:\n",
    "    imshow(np.squeeze(mask))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (unet_env)",
   "language": "python",
   "name": "unet_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
